# if you want to use caching for the builds, use `COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1 docker-compose up --build`
# There are several services commented-out in this docker-compose file. You can uncomment them if you want to use them. For kafka-related services you will need to add them to the `depends_on` section of the services that need them.

---
version: '2'

volumes:
    prometheus_data: {}
    grafana_data: {}
    influxdb2:
    redis_data:
    postgres-db:


services:

  streaming_iot:
      build:
        context: .
        #args:
        #  A: B
      image: ntua/streaming_iot
      container_name: streaming_iot
      # depends_on:
      #   -
      expose:
        - 10000
      ports:
        - 10000:10000
      volumes:
        - ./config:/config
        - ./logs:/logs
      depends_on:
        - influxdb
        - redis
        - postgres

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2

  broker:
    image: confluentinc/cp-server:7.3.0
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9991:9991"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9991
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
    #   KAFKA_HEAP_OPTS: ${KAFKA_BROKER_HEAP_OPTS}
    # mem_limit: ${KAFKA_BROKER_MEM_LIMIT}

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

  connect:
    build:
        context: ./custom_images/kafka-connect
        dockerfile: Dockerfile
    image: my_kafka_connect:latest
    hostname: connect
    container_name: connect
    depends_on:
      - broker
      - schema-registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.3.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/usr/local/share/kafka-connect-influxdb"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.3.0
    hostname: control-center
    container_name: control-center
    depends_on:
      - broker
      - schema-registry
      - connect
      # - ksqldb-server
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_CONNECT_HEALTHCHECK_ENDPOINT: '/connectors'
      CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8088"
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021
        #  volumes:
        #- ./control-center:/var/lib/confluent-control-center        

  # ksqldb-server:
  #   image: confluentinc/cp-ksqldb-server:7.3.0
  #   hostname: ksqldb-server
  #   container_name: ksqldb-server
  #   depends_on:
  #     - broker
  #     - connect
  #   ports:
  #     - "8088:8088"
  #   environment:
  #     KSQL_CONFIG_DIR: "/etc/ksql"
  #     KSQL_BOOTSTRAP_SERVERS: "broker:29092"
  #     KSQL_HOST_NAME: ksqldb-server
  #     KSQL_LISTENERS: "http://0.0.0.0:8088"
  #     KSQL_CACHE_MAX_BYTES_BUFFERING: 0
  #     KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
  #     KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
  #     KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
  #     KSQL_KSQL_CONNECT_URL: "http://connect:8083"
  #     KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
  #     KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
  #     KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'

  # ksqldb-cli:
  #   image: confluentinc/cp-ksqldb-cli:7.3.0
  #   container_name: ksqldb-cli
  #   depends_on:
  #     - broker
  #     - connect
  #     - ksqldb-server
  #   entrypoint: /bin/sh
  #   tty: true

  #ksql-datagen:
  #  image: confluentinc/ksqldb-examples:7.3.0
  #  hostname: ksql-datagen
  #  container_name: ksql-datagen
  #  depends_on:
  #    - ksqldb-server
  #    - broker
  #    - schema-registry
  #    - connect
  #  command: "bash -c 'echo Waiting for Kafka to be ready... && \
  #                     cub kafka-ready -b broker:29092 1 40 && \
  #                     echo Waiting for Confluent Schema Registry to be ready... && \
  #                     cub sr-ready schema-registry 8081 40 && \
  #                     echo Waiting a few seconds for topic creation to finish... && \
  #                     sleep 11 && \
  #                     tail -f /dev/null'"
  #  environment:
  #    KSQL_CONFIG_DIR: "/etc/ksql"
  #    STREAMS_BOOTSTRAP_SERVERS: broker:29092
  #    STREAMS_SCHEMA_REGISTRY_HOST: schema-registry
  #    STREAMS_SCHEMA_REGISTRY_PORT: 8081

  rest-proxy:
    image: confluentinc/cp-kafka-rest:7.3.0
    depends_on:
      - broker
      - schema-registry
    ports:
      - "8082:8082"
    hostname: rest-proxy
    container_name: rest-proxy
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker:29092'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'

  modbus-server:
    image: ghcr.io/pymodbus-dev/pymodbus:dev
    ports:
      - "5020:5020"
    hostname: modbus-server
    container_name: modbus-server
    command: "bash -c 'python /pymodbus/examples/server_async.py --port 5020 '"
#    --modbus-protocol-binary --modbus-protocol-rtu --modbus-protocol-ascii'"

  modbus-client:
    build:
        context: ./custom_images/modbus-client
        dockerfile: Dockerfile
    image: modbus-client
    ports:
      - "5021:5021"
    hostname: modbus-client
    container_name: modbus-client
    depends_on:
      - modbus-server

  grafana:
      image: grafana/grafana
      container_name: grafana
      #network_mode: host
      #depends_on:
      #  - prometheus
      ports:
        - 3000:3000
      volumes:
        - ./monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
        - ./monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
        - ./monitoring/grafana/config.ini:/etc/grafana/config.ini
        - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
        - grafana_data:/var/lib/grafana
      environment:
        - GF_SECURITY_ADMIN_PASSWORD=admin
        - GF_USERS_ALLOW_SIGN_UP=false
        - NO_PROXY=localhost,prometheus,grafana,127.0.0.0/8,
        - no_proxy=localhost,prometheus,grafana,127.0.0.0/8,
        # - GF_SERVER_DOMAIN=myrul.com
        # - GF_SMTP_ENABLED=true
        # - GF_SMTP_HOST=smtp.gmail.com:587
        # - GF_SMTP_USER=myadrress@gmail.com
        # - GF_SMTP_PASSWORD=mypassword
        # - GF_SMTP_FROM_ADDRESS=myaddress@gmail.com

  loki:
    image: grafana/loki
    container_name: loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml

  promtail:
    container_name: promtail
    image: grafana/promtail
#    restart: always
    volumes:
      - ./monitoring/promtail:/etc/promtail
      - ./logs:/var/log
    command: -config.file=/etc/promtail/promtail-config.yaml
  #graphite:
  #  image: graphiteapp/graphite-statsd
  #  restart: always
  #  ports:
  #    - "18081:80"
  #    - "2003-2004:2003-2004"
  #    - "2023-2024:2023-2024"
  #    - "8125:8125/udp"
  #    - "8126:8126"

  cadvisor:
      image: gcr.io/cadvisor/cadvisor
      container_name: cadvisor
      privileged: true
      volumes:
        - /:/rootfs:ro
        - /var/run:/var/run:rw
        - /sys:/sys:ro
        - /var/lib/docker/:/var/lib/docker:ro
      ports:
        - 8080:8080
      #network_mode: host

  node-exporter:
     image: prom/node-exporter:latest
     container_name: node-exporter
#     restart: unless-stopped
     volumes:
       - /proc:/host/proc:ro
       - /sys:/host/sys:ro
       - /:/rootfs:ro
     command:
       - '--path.procfs=/host/proc'
       - '--path.rootfs=/rootfs'
       - '--path.sysfs=/host/sys'
       - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
     expose:
       - 9100

  prometheus:
    image: prom/prometheus
    user: root
    container_name: prometheus
    volumes:
    # - ./monitoring/prometheus:/etc/prometheus
    - ./monitoring/prometheus/prometheus_dev.yml:/etc/prometheus/prometheus.yml
    # - ./monitoring/prometheus/rules.yml:/etc/prometheus/rules.yml
    - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      # - '-alertmanager.url=http://alertmanager:9093'
    expose:
      - 9090
    ports:
      - 9090:9090
      #- 10000:10000
    depends_on:
      - cadvisor
      # - jmx-kafka
    links:
      - cadvisor:cadvisor
#      - alertmanager:alertmanager
    #network_mode: host

  alertmanager:
    image: prom/alertmanager #:v0.23.0
#    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - "./monitoring/alertmanager:/config"
      # - alertmanager-data:/data
    command: --config.file=/config/alertmanager.yml --log.level=debug

  redis:
    image: 'bitnami/redis:latest'
    container_name: redis
    environment:
      ALLOW_EMPTY_PASSWORD: yes
    ports:
      - '6379:6379'
    volumes: 
      - redis_data:/data
    #network_mode: host

  influxdb:
    image: influxdb:latest
    container_name: influxdb2
    volumes:
      - ./influxdb/data:/var/lib/influxdb2:rw
      - ./config/kafka-connect-influxdb:/usr/local/share/kafka-connect-influxdb
    #    env_file:
#      - .env
#    entrypoint: ["./entrypoint.sh"]
    ports:
      - 8086:8086
    environment:
      INFLUXDB_DB: streaming_iot
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: admin
      DOCKER_INFLUXDB_INIT_PASSWORD: mySecurePassword
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: jSR6OM0zJplfwrs_OCHf88rlb1ClA1v46fz8PxVOLsYrANQoixVqZrqCC9iF-QWDCVnRjaa5jtK4OwBw7-skag==
      DOCKER_INFLUXDB_INIT_ORG: ntua
      DOCKER_INFLUXDB_INIT_BUCKET: streaming_iot
      DOCKER_INFLUXDB_INIT_RETENTION: 1w
#    restart: unless-stopped
## Get data from InfluxDB:
##    curl -X POST "http://localhost:8086/api/v2/query?org=ntua"   --header "Authorization: Token jSR6OM0zJplfwrs_OCHf88rlb1ClA1v46fz8PxVOLsYrANQoixVqZrqCC9iF-QWDCVnRjaa5jtK4OwBw7-skag=="   --header "Content-Type: application/vnd.flux"   --data 'query=from(bucket:"streaming_iot") |> range(start:-1h) |> filter(fn:(r) => r._measurement == "aggregated_measurement") |> yield()'
## for a specific device:
##    curl -X POST "http://localhost:8086/api/v2/query?org=ntua"   --header "Authorization: Token jSR6OM0zJplfwrs_OCHf88rlb1ClA1v46fz8PxVOLsYrANQoixVqZrqCC9iF-QWDCVnRjaa5jtK4OwBw7-skag=="   --header "Content-Type: application/vnd.flux"   --data 'query=from(bucket:"streaming_iot") |> range(start:-1h) |> filter(fn:(r) => r._measurement == "aggregated_measurement" and r.sensor_id == "temp-1") |> yield()'

  # jmx-kafka:
  #   image: "sscaling/jmx-prometheus-exporter"
  #   ports:
  #    - "5556:5556"
  #   environment:
  #    CONFIG_YML : "/etc/jmx_exporter/config.yml"
  #    JVM_OPTS: ${PROMETHEUS_JMX_AGENT_JVM_OPTS}
  #    JMX_URL: service:jmx:rmi:///jndi/rmi://broker:9991/jmxrmi
  #   volumes:
  #    - ./monitoring/jmx_exporter/config_kafka.yml:/etc/jmx_exporter/config.yml
  #   container_name: jmx-kafka
  #   depends_on:
  #    - broker

#  telegraf:
#    image: telegraf:latest
#    container_name: telegraf
##    links:
##      - influxdb
#    volumes:
#      #  Sync timezone with host
#      - /etc/localtime:/etc/localtime:ro
#      #  Map Telegraf configuration file
#      #- /mnt/influxdb/telegraf.conf:/etc/telegraf/telegraf.conf:ro
#      #  Map /tmp to permanent storage  (this includes /tmp/metrics.out)
#      - /mnt/influxdb:/tmp:rw
#    restart: unless-stopped
#    depends_on:
#      - influxdb


  # zoonavigator:
  #   image: elkozmon/zoonavigator:${ZOONAVIGATOR_VERSION}
  #   container_name: zoonavigator
  #   ports:
  #     - "8000:8000"
  #   environment:
  #     HTTP_PORT: 8000
  #     AUTO_CONNECT_CONNECTION_STRING: zookeeper:2181
  #   depends_on:
  #     - zookeeper


  postgres:
    container_name: postgres
    image: postgres:15-alpine3.18
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: SomeSecretPassword
      PGDATA: /data/postgres
    volumes:
      - postgres-db:/data/postgres
    ports:
      - "5432:5432"