#spring.main.banner-mode: off
debug: false

web-server-only: false

server:
   port: 10000
   shutdown: graceful
   servlet.context-path: /streaming-iot

management:
   endpoints:
      web:
         base-path: /manage
         exposure:
            include: "*"
            exclude: heapdump
   endpoint:
      health:
         show-details: ALWAYS
         group:
            health-group.include: ping, diskSpace
   info:
      build.enabled: true
      env.enabled: true
      git.enabled: true
      #git.mode: full
      java.enabled: true
      os.enabled: true
   metrics:
      allowed:
      #allowed: '*'
      #allowed: spring, jvm, gc, kafka, service, component, repository, hikaricp, http, application, system, disk, executor
      #enable:
      #  all: true
      #  appinfo: true
      #  hikaricp: true
      registries: prometheus # jmx, graphite
      export.graphite:
         enabled: false # only for graphite
         host: localhost
         port: 2004
         step: 5s
         instance-id: ip # Valid auto-modes: ip, host, fqdn, jvmid, uuid
      #export.prometheus:
      #  descriptions: false
      #  step: 10s
spring:
   application.name: streaming-iot
   banner.location: classpath:banner.txt
#   autoconfigure:
#      exclude: org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration

#   mvc:
#      pathmatch:
#         matching-strategy: ant_path_matcher
   datasource:
      url: jdbc:h2:mem:ntua
      username: admin
      password: mySecurePassword
      driverClassName: org.h2.Driver
   jpa:
      spring.jpa.database-platform: org.hibernate.dialect.H2Dialect
   boot:
      admin:
         client: 
            enabled: true
            auto-registration: true
            url: http://localhost:10000/streaming-iot
         routes.endpoints: env, metrics, trace, jolokia, info, configprops
   redis:
      host: localhost
      port: 6379
#      password: mySecurePassword
   # Kafka
   kafka:
      properties:
         sasl.mechanism: PLAIN
         bootstrap.servers: 127.0.0.1:9092
         sasl.jaas.config: org.apache.kafka.common.security.plain.plain
         security.protocol: PLAINTEXT
         #bootstrap.servers: pkc-03vj5.europe-west8.gcp.confluent.cloud:9092
         #sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule   required username: '752B2VK3WEHE47P5'   password: 'VxO0/2tkxDt2X5cQjloTskpDaZkLijv8Db4CKt7baEQQ1cHqIrWU2WApmpdbnfNb';
         #security.protocol: SASL_SSL
      producer:
         key-serializer: org.apache.kafka.common.serialization.IntegerSerializer
         value-serializer: org.apache.kafka.common.serialization.IntegerSerializer
         client-id: spring-boot-producer
         acks: 1 # Number of acknowledgments the producer requires the leader to have received before considering a request complete.
         retries: 3 # enables retrying of failed sends.
         batch-size: 16384 # send batch when full or linger.ms has passed
         buffer-memory: 33554432 # Total memory size the producer can use to buffer records waiting to be sent to the server.
         properties:
            linger:
               ms: 1000 # wait before sending batch
      consumer:
         key-deserializer: org.apache.kafka.common.serialization.IntegerDeserializer
         value-deserializer: org.apache.kafka.common.serialization.IntegerDeserializer
         fetch-max-wait: 1000 # Maximum amount of time the server blocks before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by "fetch-min-size".
         fetch-min-size: 1 # Minimum amount of data the server should return for a fetch request.
         max-poll-records: 1000 # Maximum number of records returned in a single call to poll().
         auto-offset-reset: earliest # What to do when there is no initial offset in Kafka or if the current offset no longer exists on the server.
         enable-auto-commit: false # Whether the consumer's offset is periodically committed in the background.
         auto-commit-interval: 15 # Frequency with which the consumer offsets are auto-committed to Kafka if 'enable.auto.commit' is set to true.
         group-id: group1
         properties:
            deadletterqueue.topic.name: deadletterQueue
            default:
               deserialization.exception.handler.class: org.springframework.kafka.listener.DeadLetterPublishingRecoverer
      streams:
         replication-factor: 1
         application-id: spring-boot-streams
      retry:
         topic.max-delay: 15 # Maximum wait between retries. If less than the delay then the default of 30 seconds is applied.
      

application:
   security:
      enabled: false
   influxdb:
      host: localhost
      port: 8086
      database: streaming-iot
      username: admin
      password: mySecurePassword
      token: jSR6OM0zJplfwrs_OCHf88rlb1ClA1v46fz8PxVOLsYrANQoixVqZrqCC9iF-QWDCVnRjaa5jtK4OwBw7-skag==
#      token: adminToken
      org: ntua
      bucket: streaming_iot
      retention: 15d
   schema.registry:
      host: localhost
      port: 8081
   modbusPal:
      host: localhost
      port: 5020
   producer:
      produceIntervalSec: 1
      fakeProducer:
         enabled: false
      plc4xProducer:
         enabled: true
   consumer:
      aggregator:
         aggregateWindowSizeSec: 10
         gracePeriodSec: 5
   topics:
      measurementTopicsCount: 3
      temperature:
         measurementTopicId: 0
         devicesNum: 3
         name:
            input: streaming.input.temperatureMeasurements # Celsius
            output: streaming.output.temperatureMeasurements
         replicas: 1
      pressure: 
         measurementTopicId: 1
         devicesNum: 2
         name:
            input: streaming.input.pressureMeasurements # PSI
            output: streaming.output.pressureMeasurements 
         replicas: 1
      power:
         measurementTopicId: 2
         devicesNum: 2
         name:
            input: streaming.input.powerMeasurements # Watts
            output: streaming.output.powerMeasurements
         replicas: 1

springdoc: 
  show-actuator: true
#  swagger-ui.path: /swagger-ui.html
  api-docs:
    enabled: true
    path: /api-docs
    #use-management-port: true

logging:
   config: config/logback.xml
   file.name: ./logs/streaming-iot.log
   #pattern:
   #   # console: %d{yyyy-MM-dd HH:mm:ss} - %msg%n
   #   file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
   #rollingpolicy:
   #   file-name-pattern: logs/archived/streaming-iot_%d{dd-MM-yyyy}-%i.log
   #   max-file-size: 10MB
   #   max-history: 10
   #   total-size-cap: 100MB
   #   clean-history-on-start: true
   level:
      _org.springframework.web.servlet.HandlerMapping.Mappings: debug


#    set logging of my app to TRACE
logging.level: TRACE

---
spring:
   config:
      activate:
         on-profile: docker
management.metrics.export.graphite.host: graphite
spring.kafka.bootstrap.servers: broker:9092
spring.kafka.properties.bootstrap.servers: broker:9092
application.influxdb.host: influxdb2
application.schema.registry.host: schema-registry
